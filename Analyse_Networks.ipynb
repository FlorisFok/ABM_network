{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read my pickle\n",
    "# data = pickle.load(open(\"individuals_friendships_utilities.p\",\"rb\"))\n",
    "# characteristics, connectivity, utilities = data\n",
    "\n",
    "g_list = pickle.load(open(\"g_list.pkl\", \"rb\"))\n",
    "X_list = pickle.load(open(\"X_list.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109, 109)\n",
      "[[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(109, 3)\n",
      "[[ 2  1 10]\n",
      " [ 1  1  7]\n",
      " [ 2  1 12]\n",
      " [ 1  1  9]\n",
      " [ 1  1 11]\n",
      " [ 1  1 11]\n",
      " [ 2  1  7]\n",
      " [ 1  1  7]\n",
      " [ 1  1  8]\n",
      " [ 1  1 12]\n",
      " [ 2  1  7]\n",
      " [ 1  1 12]\n",
      " [ 1  1  9]\n",
      " [ 1  1  7]\n",
      " [ 2  1 11]\n",
      " [ 1  1  9]\n",
      " [ 1  1  9]\n",
      " [ 2  1  7]\n",
      " [ 1  1 10]\n",
      " [ 1  1 12]\n",
      " [ 2  1 11]\n",
      " [ 1  1  7]\n",
      " [ 1  1  9]\n",
      " [ 1  1 12]\n",
      " [ 2  5 10]\n",
      " [ 2  1  7]\n",
      " [ 1  1  9]\n",
      " [ 2  1 12]\n",
      " [ 1  1  7]\n",
      " [ 1  1  7]\n",
      " [ 2  1 10]\n",
      " [ 1  1  8]\n",
      " [ 1  1  7]\n",
      " [ 1  1 10]\n",
      " [ 1  1  8]\n",
      " [ 1  1 11]\n",
      " [ 1  1 11]\n",
      " [ 2  1 10]\n",
      " [ 2  1  8]\n",
      " [ 2  1 12]\n",
      " [ 1  1 10]\n",
      " [ 1  5  8]\n",
      " [ 1  1  9]\n",
      " [ 1  1 12]\n",
      " [ 2  1 12]\n",
      " [ 1  3  9]\n",
      " [ 1  1 10]\n",
      " [ 2  1  8]\n",
      " [ 1  1  8]\n",
      " [ 1  1 11]\n",
      " [ 2  1 12]\n",
      " [ 2  1  7]\n",
      " [ 2  5  9]\n",
      " [ 1  1  8]\n",
      " [ 2  1  8]\n",
      " [ 1  1 10]\n",
      " [ 1  5 12]\n",
      " [ 2  1  9]\n",
      " [ 1  1 11]\n",
      " [ 1  3  7]\n",
      " [ 1  1 12]\n",
      " [ 1  1  8]\n",
      " [ 1  1 11]\n",
      " [ 1  1  8]\n",
      " [ 2  1  9]\n",
      " [ 1  1 10]\n",
      " [ 2  1 10]\n",
      " [ 1  1  8]\n",
      " [ 1  1 10]\n",
      " [ 1  1 10]\n",
      " [ 2  1 10]\n",
      " [ 2  1  7]\n",
      " [ 2  1  9]\n",
      " [ 1  1  7]\n",
      " [ 2  1 12]\n",
      " [ 2  1 12]\n",
      " [ 2  1  7]\n",
      " [ 1  1 12]\n",
      " [ 2  1  8]\n",
      " [ 1  1  7]\n",
      " [ 2  1 12]\n",
      " [ 2  1 12]\n",
      " [ 1  1  7]\n",
      " [ 2  1 11]\n",
      " [ 1  1  7]\n",
      " [ 1  1  7]\n",
      " [ 1  1  8]\n",
      " [ 2  5  9]\n",
      " [ 1  1  8]\n",
      " [ 2  1  8]\n",
      " [ 1  1  7]\n",
      " [ 1  1  8]\n",
      " [ 1  1 10]\n",
      " [ 2  1 10]\n",
      " [ 2  1 12]\n",
      " [ 1  1  7]\n",
      " [ 1  1  7]\n",
      " [ 2  1  9]\n",
      " [ 1  1 12]\n",
      " [ 1  1  9]\n",
      " [ 2  1 10]\n",
      " [ 2  1  8]\n",
      " [ 2  5  7]\n",
      " [ 1  1  9]\n",
      " [ 2  1 12]\n",
      " [ 1  1 11]\n",
      " [ 1  1 12]\n",
      " [ 2  1  9]\n",
      " [ 2  1  9]]\n"
     ]
    }
   ],
   "source": [
    "connectivity = g_list[1]\n",
    "print(connectivity.shape)\n",
    "print(connectivity)\n",
    "characteristics = X_list[1]\n",
    "charac_short = characteristics[:,0:3]\n",
    "print(charac_short.shape)\n",
    "print(charac_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7214576962283384,\n",
       " 0.41009174311926605,\n",
       " 0.2808022922636103,\n",
       " 0.41640636493060856,\n",
       " [0.32442072614486406, 0.20200116408940086])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyse_network(connectivity, characteristics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 0]\n",
      " [1 0 1 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "4\n",
      "[[ 2  1 10]\n",
      " [ 1  1  7]\n",
      " [ 2  1 12]\n",
      " [ 1  1  9]]\n"
     ]
    }
   ],
   "source": [
    "small = np.array([[0,1,1,0],\n",
    "                 [1,0,1,0],\n",
    "                 [0,0,0,0],\n",
    "                 [0,0,0,0]])\n",
    "print(small)\n",
    "print(np.sum(small))\n",
    "\n",
    "charac_mini = charac_short[0:4]\n",
    "print(charac_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1 1]\n",
      " [1 0 1 1 0]\n",
      " [1 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [1 0 1 1 0]]\n",
      "12\n",
      "[[ 2  1 10]\n",
      " [ 1  1  7]\n",
      " [ 2  1 12]\n",
      " [ 1  1  9]\n",
      " [ 1  1 11]]\n"
     ]
    }
   ],
   "source": [
    "small5 = np.array([[0,1,1,1,1],\n",
    "                 [1,0,1,1,0],\n",
    "                 [1,0,0,0,0],\n",
    "                 [1,0,0,0,0],\n",
    "                  [1,0,1,1,0]])\n",
    "print(small5)\n",
    "print(np.sum(small5))\n",
    "\n",
    "charac_mini5 = charac_short[0:5]\n",
    "print(charac_mini5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.25,\n",
       " 0.24,\n",
       " 0.5,\n",
       " 0.23809523809523808,\n",
       " [0.5555555555555555, 0.15713484026367722],\n",
       " {'0_1': 0.2857142857142857,\n",
       "  '0_2': 0.4,\n",
       "  '1_1': 1.0,\n",
       "  '2_10': 0.0,\n",
       "  '2_11': 0.0,\n",
       "  '2_12': 0.0,\n",
       "  '2_7': 0.0,\n",
       "  '2_9': 0.0})"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyse_network(small5, charac_mini5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output:\n",
    "# den_max_reach / density at maximum reach (RCHDEN): density of the reachability network \n",
    "# rel_den / relative density (RELDEN): amount of nodes divided by the maximum possible number of nodes\n",
    "# p_symm_dyads / proportion symmetric dyads (PTCMUT): proportion of nodes that are reciprocal (counting once)\n",
    "# mutuality_index / mutuality index (RHO2): Katz and Powell’s (1955) mutuality index. Measures the tendency for actors in a group to reciprocate choices.\n",
    "den_max_reach, rel_den, p_symm_dyads, mutuality_index, clustering_coefficient = analyse_network(small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_network(connectivity, characteristics):\n",
    "    # Output:\n",
    "    # density at maximum reach (RCHDEN), > den_max_reach\n",
    "    # relative density (RELDEN), > rel_den\n",
    "    # proportion symmetric dyads (PTCMUT), > p_symm_dyads \n",
    "    # mutuality index (RHO2), > mutuality_index\n",
    "    # clustering_coefficient\n",
    "    # homophily index per trait in dict > homoph_ind (\"sex_\", \"race_\", \"grade_\") # NOW BASED ON NOMINATIONS/OUT-DEGREE\n",
    "    # ?ADD? segregation index per trait in tuple > segreg_ind (sex, race, grade)\n",
    "    # ?ADD? salience index per trait in tuple > salien_ind (sex, race, grade)\n",
    "    \n",
    "    # input: \n",
    "    # connectivity matrix with students claiming to have friends in row and students claimed to be befriended in columns\n",
    "    \n",
    "    nodes = connectivity.shape[0]\n",
    "    mutual_d = 0\n",
    "    asym_d = 0\n",
    "    out_degrees = []\n",
    "    trait = [\"sex\", \"race\", \"grade\"]\n",
    "    \n",
    "    \n",
    "    #density DENX2\n",
    "    #DENX2 = np.sum(connectivity)/(nodes*(nodes-1))\n",
    "    \n",
    "    \n",
    "    # density at maximum reach RCHDEN\n",
    "    \n",
    "    # define the function to tranfer adjacency matrix to reachability matrix  \n",
    "    # Prints reachability matrix of graph[][] using Floyd Warshall algorithm \n",
    "    # function found on https://www.geeksforgeeks.org/transitive-closure-of-a-graph/\n",
    "    reachability = copy.deepcopy(connectivity)\n",
    "    '''reach[][] will be the output matrix that will finally \n",
    "    have reachability values. \n",
    "    Initialize the solution matrix same as input graph matrix'''\n",
    "    reach =[i[:] for i in reachability] \n",
    "    '''Add all vertices one by one to the set of intermediate \n",
    "    vertices. \n",
    "    ---> Before start of a iteration, we have reachability value \n",
    "    for all pairs of vertices such that the reachability values \n",
    "    consider only the vertices in set  \n",
    "    {0, 1, 2, .. k-1} as intermediate vertices. \n",
    "    ----> After the end of an iteration, vertex no. k is \n",
    "    added to the set of intermediate vertices and the  \n",
    "    set becomes {0, 1, 2, .. k}'''\n",
    "    for k in range(nodes): \n",
    "              \n",
    "        # Pick all vertices as source one by one \n",
    "        for i in range(nodes): \n",
    "                  \n",
    "            # Pick all vertices as destination for the \n",
    "            # above picked source \n",
    "            for j in range(nodes): \n",
    "                      \n",
    "                # If vertex k is on a path from i to j,  \n",
    "                    # then make sure that the value of reach[i][j] is 1 \n",
    "                reach[i][j] = reach[i][j] or (reach[i][k] and reach[k][j]) \n",
    "    \n",
    "    RCHDEN = np.sum(reach)/(nodes*(nodes-1))\n",
    "    \n",
    "    \n",
    "    # relative density RELDEN\n",
    "    RELDEN = np.sum(connectivity)/(10*nodes)\n",
    "\n",
    "\n",
    "    # create upper triangular matrix with 2's on mutual dyads, 1's on asymmetric dyads and count occurrence\n",
    "    added_up = np.triu(connectivity + np.transpose(connectivity))\n",
    "    mutual_d = np.count_nonzero(added_up == 2)\n",
    "    asym_d = np.count_nonzero(added_up == 1)\n",
    "    total_d = mutual_d + asym_d\n",
    "    \n",
    "    # calculate proportion symmetric dyads (PTCMUT) and asymmetric dyads (PTCASY)\n",
    "    PTCMUT = mutual_d / total_d\n",
    "    #PTCASY = asym_d / total_d\n",
    "    \n",
    "    \n",
    "    # count total out_degree connections\n",
    "    out_degree = connectivity.sum()\n",
    "    # take the sum of squares of the out degree connections per individual (row)\n",
    "    sum_squares_out = (connectivity.sum(axis=1)**2).sum()\n",
    "    \n",
    "    # calculate mutuality index (RHO2) (according to Katz and Powell’s (1955))\n",
    "    RHO2 = (2*(nodes - 1)**2 * mutual_d - out_degree**2 + sum_squares_out) / (out_degree*(nodes - 1)**2 - out_degree**2 + sum_squares_out)\n",
    "    \n",
    "    # determine the local clustering coefficient mean and standard deviation\n",
    "    clustering_coefficients = []\n",
    "    for n_node, connections in enumerate(connectivity):\n",
    "        # the amount of neighbours each node has\n",
    "        n_neighbours = np.sum(connectivity[n_node])\n",
    "        # only consider nodes with at least 2 neighbours\n",
    "        if n_neighbours >= 2:\n",
    "            # matrix of the nodes that are both neighbours of the node considered\n",
    "            neighbour_matrix = np.dot(np.transpose([connectivity[n_node]]),[connectivity[n_node]])\n",
    "            # the amount of connections between neighbours\n",
    "            neighbour_connections = np.sum(connectivity*neighbour_matrix)\n",
    "            # the amount of connections between neighbours divided by the possible amount of connections\n",
    "            clustering_coefficients.append(neighbour_connections / (n_neighbours*(n_neighbours-1)))\n",
    "    mean_clustering_coefficient = np.mean(clustering_coefficients)\n",
    "    std_clustering_coefficient = np.std(clustering_coefficients)\n",
    "    clustering_coefficient = [mean_clustering_coefficient,std_clustering_coefficient]\n",
    "    \n",
    "    \n",
    "    # create homophily index dictionary\n",
    "    homoph_ind = dict()\n",
    "    # iterate through different characteristics (sex, race, grade)\n",
    "    for i in range(characteristics.shape[1]):\n",
    "        # get different groups of this characteristic in dataset\n",
    "        characs = sorted(list(set(characteristics[:,i])))\n",
    "        # iterate through different groups of this characteristic\n",
    "        for j in range(len(characs)):\n",
    "            # indicate indices of members this group\n",
    "            indices = np.where(characteristics[:,i] == characs[j])[0]\n",
    "            \n",
    "            # create 2 submatrices outgoing connections: 1 to individuals same group and 1 to individuals different group\n",
    "            submat_same = connectivity[np.ix_(indices,indices)]\n",
    "            mask = np.ones(connectivity.shape[0], np.bool)\n",
    "            mask[indices] = 0\n",
    "            submat_diff = (connectivity[np.ix_(indices,)])[:,mask]\n",
    "            \n",
    "            # count amount outgoing connections to same and to different group\n",
    "            out_same = np.mean(submat_same.sum(axis=1))\n",
    "            out_diff = np.mean(submat_diff.sum(axis=1))\n",
    "            \n",
    "            # calculate and save homophily index from this group for this characteristic\n",
    "            homoph_ind[str(trait[i]) + \"_\" + str(characs[j])] = out_same / (out_same + out_diff)\n",
    "            \n",
    "    \n",
    "    return RCHDEN, RELDEN, PTCMUT, RHO2, clustering_coefficient, homoph_ind\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7214576962283384,\n",
       " 0.41009174311926605,\n",
       " 0.2808022922636103,\n",
       " 0.41640636493060856,\n",
       " [0.32442072614486406, 0.20200116408940086],\n",
       " {'grade_10': 0.6122448979591837,\n",
       "  'grade_11': 0.6666666666666666,\n",
       "  'grade_12': 0.8139534883720931,\n",
       "  'grade_7': 0.8321678321678322,\n",
       "  'grade_8': 0.8,\n",
       "  'grade_9': 0.5135135135135136,\n",
       "  'race_1': 0.9447115384615384,\n",
       "  'race_3': 0.0,\n",
       "  'race_5': 0.0,\n",
       "  'sex_1': 0.5807692307692308,\n",
       "  'sex_2': 0.6310160427807486})"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyse_network(connectivity, charac_short)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
